{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_order_of_candidates(line):\n",
    "    words = [s.lower() for s in line.split()]\n",
    "    trump_index = words.index(\"trump\")\n",
    "    clinton_index = words.index(\"clinton\")\n",
    "    johnson_index = words.index(\"johnson\")\n",
    "    return (trump_index < clinton_index) and (clinton_index < johnson_index)\n",
    "\n",
    "def find_row_range(filename):\n",
    "    try:\n",
    "        with open(filename) as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if \"TRUMP\" in line:\n",
    "                    assert check_order_of_candidates(line)\n",
    "                if \"President\" in line:\n",
    "                    start = i + 2\n",
    "                if \"Totals:\" in line:\n",
    "                    stop = i - 1\n",
    "                    return start, stop - start\n",
    "    except Exception as e:\n",
    "        print(filename)\n",
    "        print(e)\n",
    "        assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_suffixes = {\n",
    "    \"Election Day\": \"_ED\",\n",
    "    \"Absentee by Mail\": \"_AB\",\n",
    "    \"Absentee By Mail\": \"_AB\",\n",
    "    \"Advance in Person\": \"_AD\",\n",
    "    \"Advance In Person\": \"_AD\",\n",
    "    \"Provisional\": \"_PR\",\n",
    "    \"Choice Total\": \"\",\n",
    "}\n",
    "\n",
    "column_map = {\n",
    "    \"Registered Voters\": \"REG_VOTE\",\n",
    "    \"Precinct\": \"PRECINCT\",\n",
    "}\n",
    "\n",
    "candidate_map = {\n",
    "    \"\": \"PRES16R\",\n",
    "    \".1\": \"PRES16D\",\n",
    "    \".2\": \"PRES16L\"\n",
    "}\n",
    "\n",
    "for identifier, candidate_col in candidate_map.items():\n",
    "    for col, suffix in column_suffixes.items():\n",
    "        column_map[col + identifier] = candidate_col + suffix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_advance_columns(df):\n",
    "    num_columns = 0\n",
    "    cols = [col for col in df.columns if \"advance in person\" in col.lower() and \".\" not in col]\n",
    "    if len(cols) > 1:\n",
    "        advance_columns_map = {\n",
    "            suffix: [f\"{col}{suffix}\" for col in cols]\n",
    "            for suffix in [\"\", \".1\", \".2\"]\n",
    "        }\n",
    "        for suffix, advance_columns in advance_columns_map.items():\n",
    "            df[\"Advance in Person\" + suffix] = df[advance_columns].sum(axis=1)\n",
    "        columns_to_drop = [col for cols in advance_columns_map.values() for col in cols]\n",
    "        for suffix in advance_columns_map:\n",
    "            if \"Advance in Person\" + suffix in columns_to_drop:\n",
    "                columns_to_drop.remove(\"Advance in Person\" + suffix)\n",
    "        return df.drop(columns_to_drop, axis=\"columns\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_county_txt(county):\n",
    "    filename = f\"./data/{county}/detail.txt\"\n",
    "    skiprows, nrows = find_row_range(filename)\n",
    "    df = pandas.read_csv(filename, sep=\"\\s\\s+\", skiprows=skiprows, nrows=nrows, engine=\"python\")\n",
    "    df = sum_advance_columns(df)\n",
    "    result = df.rename(column_map, axis=\"columns\").drop(\"Total\", axis=\"columns\")\n",
    "    result[\"COUNTY\"] = county\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = os.listdir(\"./data/\")\n",
    "county_dataframes = [read_county_txt(county) for county in counties]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = set(county_dataframes[0].columns)\n",
    "\n",
    "for df in county_dataframes:\n",
    "    if set(df.columns) != columns:\n",
    "        print(columns - set(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MGGG\\Miniconda3\\envs\\max\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pandas.concat(county_dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = {\"Ben_Hill\": \"Ben Hill\", \"Jeff_Davis\": \"Jeff Davis\"}\n",
    "df[\"COUNTY\"] = df[\"COUNTY\"].apply(lambda p: new_names.get(p, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Appling', 'Atkinson', 'Bacon', 'Baker', 'Baldwin', 'Banks',\n",
       "       'Barrow', 'Bartow', 'Ben Hill', 'Berrien', 'Bibb', 'Bleckley',\n",
       "       'Brantley', 'Brooks', 'Bryan', 'Bulloch', 'Burke', 'Butts',\n",
       "       'Calhoun', 'Camden', 'Candler', 'Carroll', 'Catoosa', 'Charlton',\n",
       "       'Chatham', 'Chattahoochee', 'Chattooga', 'Cherokee', 'Clarke',\n",
       "       'Clay', 'Clayton', 'Clinch', 'Cobb', 'Coffee', 'Colquitt',\n",
       "       'Columbia', 'Cook', 'Coweta', 'Crawford', 'Crisp', 'Dade',\n",
       "       'Dawson', 'Decatur', 'DeKalb', 'Dodge', 'Dooly', 'Dougherty',\n",
       "       'Douglas', 'Early', 'Echols', 'Effingham', 'Elbert', 'Emanuel',\n",
       "       'Evans', 'Fannin', 'Fayette', 'Floyd', 'Forsyth', 'Franklin',\n",
       "       'Fulton', 'Gilmer', 'Glascock', 'Glynn', 'Gordon', 'Grady',\n",
       "       'Greene', 'Gwinnett', 'Habersham', 'Hall', 'Hancock', 'Haralson',\n",
       "       'Harris', 'Hart', 'Heard', 'Henry', 'Houston', 'Irwin', 'Jackson',\n",
       "       'Jasper', 'Jefferson', 'Jeff Davis', 'Jenkins', 'Johnson', 'Jones',\n",
       "       'Lamar', 'Lanier', 'Laurens', 'Lee', 'Liberty', 'Lincoln', 'Long',\n",
       "       'Lowndes', 'Lumpkin', 'Macon', 'Madison', 'Marion', 'McDuffie',\n",
       "       'McIntosh', 'Meriwether', 'Miller', 'Mitchell', 'Monroe',\n",
       "       'Montgomery', 'Morgan', 'Murray', 'Muscogee', 'Newton', 'Oconee',\n",
       "       'Oglethorpe', 'Paulding', 'Peach', 'Pickens', 'Pierce', 'Pike',\n",
       "       'Polk', 'Pulaski', 'Putnam', 'Quitman', 'Rabun', 'Randolph',\n",
       "       'Richmond', 'Rockdale', 'Schley', 'Screven', 'Seminole',\n",
       "       'Spalding', 'Stephens', 'Stewart', 'Sumter', 'Talbot',\n",
       "       'Taliaferro', 'Tattnall', 'Taylor', 'Telfair', 'Terrell', 'Thomas',\n",
       "       'Tift', 'Toombs', 'Towns', 'Treutlen', 'Troup', 'Turner', 'Twiggs',\n",
       "       'Union', 'Upson', 'Walker', 'Walton', 'Ware', 'Warren',\n",
       "       'Washington', 'Wayne', 'Webster', 'Wheeler', 'White', 'Whitfield',\n",
       "       'Wilcox', 'Wilkes', 'Wilkinson', 'Worth'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.COUNTY.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./GA_precincts_with_absentee.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring counties into alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = geopandas.read_file(\"./shapefiles/GA_precincts16.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = {\"CHATTOOGA\": \"Chattooga\"}\n",
    "gdf[\"CTYNAME\"] = gdf[\"CTYNAME\"].apply(lambda n: new_names.get(n, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(gdf[\"CTYNAME\"]) == set(df[\"COUNTY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(\"./shapefiles/GA_precincts16.shp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
